{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0812427c",
   "metadata": {},
   "source": [
    "# PBL Fase 6 — Entrega 2\n",
    "## Comparativo: YOLO custom (Entrega 1) × YOLO padrão × CNN do zero\n",
    "\n",
    "**Objetivo**: Reutilizar o mesmo dataset da Entrega 1 e comparar:\n",
    "1. **YOLO customizada** (treinada na Entrega 1).\n",
    "2. **YOLO padrão (baseline)** — ex.: `yolov5s`/`yolov8n` treinada do zero no *seu* dataset.\n",
    "3. **CNN do zero** (classificação A vs B).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9632146c",
   "metadata": {},
   "source": [
    "## 0) Preparação do ambiente (Colab)\n",
    "- Conectar Google Drive\n",
    "- Instalar dependências YOLOv5 e Ultralytics (YOLOv8)\n",
    "- Configurar variáveis de caminho\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18a55573",
   "metadata": {},
   "source": [
    "## 1) Definição dos caminhos e parâmetros do dataset\n",
    "Preencha de acordo com **a mesma estrutura da sua Entrega 1**.\n",
    "\n",
    "- `DATASET_DIR`: pasta raiz contendo `images` e `labels` por split (YOLO) ou pastas por classe (classificação).\n",
    "- `DATA_YAML`: arquivo `.yaml` do YOLO com `train`, `val`, (opcional `test`) e `names`.\n",
    "\n",
    "> `DATA_YAML = \"/content/drive/MyDrive/training-ia-test/barco/barco.yaml\"`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c21af0d",
   "metadata": {},
   "source": [
    "## 2) Utilitários de benchmark\n",
    "Funções auxiliares para medir tempo de **treinamento** e **inferência**, e consolidar métricas.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cadfa6f",
   "metadata": {},
   "source": [
    "## 3) YOLO Custom (reuso da Entrega 1)\n",
    "- Reutilize seus **pesos treinados** na Entrega 1 (ex.: `runs/train/expX/weights/best.pt`).\n",
    "- Avalie no conjunto de **teste** e colete métricas (**mAP**, **precision**, **recall**, etc.).\n",
    "- Meça **tempo de inferência** em um lote de imagens de teste.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0360a007",
   "metadata": {},
   "source": [
    "## 4) YOLO Padrão (baseline) — Treino do zero\n",
    "Treine um modelo leve (ex.: `yolov5s`) por **duas configurações de épocas** (30 e 60). Colete métricas de validação/teste e compare.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5b956b5",
   "metadata": {},
   "source": [
    "## 5) Preparação para CNN (classificação)\n",
    "A CNN requer **pastas por classe** (ex.: `train/A`, `train/B`, `val/A`…). Se seu dataset está em formato YOLO (imagens + labels), usa-se uma regra simples:\n",
    "\n",
    "- Para cada imagem, lê-se o arquivo `.txt` com `class_id x_center y_center width height`.\n",
    "- A classe **majoritária na imagem** define o rótulo de **classificação da imagem**.\n",
    "- Caso haja empate ou múltiplos objetos, você pode **definir manualmente** ou **pular a imagem**.\n",
    "\n",
    "> Ajuste `YOLO_IMAGES_DIR` e `YOLO_LABELS_DIR` conforme sua estrutura.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bef760f",
   "metadata": {},
   "source": [
    "## 6) CNN do zero (PyTorch)\n",
    "Treina uma CNN simples para **classificar A vs B**. Coletamos **accuracy/precision/recall/F1** e **tempo de treino**. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de4aea8d",
   "metadata": {},
   "source": [
    "## 7) Consolidação e comparação\n",
    "Monte uma tabela comparando **precisão**, **F1**, **tempo de treino**, **tempo de inferência** e, quando possível, **mAP** (YOLO). Registre observações qualitativas (facilidade de uso/integração, tamanho do modelo, etc.).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba629ee9",
   "metadata": {},
   "source": [
    "## 8) Análise crítica (Markdown)\n",
    "- **Facilidade de uso/integração**: YOLOv5/YOLOv8 têm APIs prontas, require anotação bbox. CNN exige dataset por classe, mas é simples para *classificação pura*.\n",
    "- **Precisão do modelo**: YOLO para **detecção** (mAP); CNN para **classificação** (accuracy/F1). Pode variar com balanceamento, qualidade e tamanho da base.\n",
    "- **Tempo de treinamento/customização**: comparar 30 vs 60 épocas para ambas abordagens.\n",
    "- **Tempo de inferência**: medir ms/imagem em GPU/CPU quando possível; YOLOv5s/YOLOv8n são rápidos.\n",
    "- **Quando usar cada uma**: detecção (localizar + classificar) vs classificação (decidir qual classe global).\n",
    "\n",
    "> **Limitações**: dataset pequeno (80 imagens) pode levar a overfitting.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be2292bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# === Monta o Google Drive ===\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# === Clona YOLOv5 e instala dependências ===\n",
    "!git clone https://github.com/ultralytics/yolov5.git\n",
    "!pip install -r yolov5/requirements.txt -q\n",
    "\n",
    "# === Instala Ultralytics (YOLOv8) opcionalmente ===\n",
    "!pip install ultralytics -q\n",
    "\n",
    "# === Imports comuns ===\n",
    "import os, time, json, shutil, glob, re, math, random\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfe504ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "DATA_YAML = \"/content/drive/MyDrive/training-ia-test/barco/barco.yaml\"  \n",
    "DATASET_DIR = \"/content/drive/MyDrive/training-ia-test/barco\"  \n",
    "\n",
    "CLASS_NAMES = None  # ex.: [\"barco\", \"nao_barco\"]\n",
    "\n",
    "# Tamanho de imagem\n",
    "IMG_SIZE_YOLO = 640\n",
    "IMG_SIZE_CNN  = 224\n",
    "\n",
    "# Épocas para comparação\n",
    "EPOCHS_LIST = [30, 60]  # conforme enunciado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ef33430",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Tenta ler os nomes das classes do YAML (modo simples)\n",
    "def load_names_from_yaml(yaml_path):\n",
    "    try:\n",
    "        import yaml\n",
    "        with open(yaml_path, 'r') as f:\n",
    "            data = yaml.safe_load(f)\n",
    "        if isinstance(data.get('names'), list):\n",
    "            return [str(x) for x in data['names']]\n",
    "        elif isinstance(data.get('names'), dict):\n",
    "            # dict {id: name}\n",
    "            return [data['names'][k] for k in sorted(data['names'])]\n",
    "    except Exception as e:\n",
    "        print(\"Não foi possível ler names do YAML:\", e)\n",
    "    return None\n",
    "\n",
    "if CLASS_NAMES is None:\n",
    "    try:\n",
    "        from google.colab import drive  # sanity check for Colab\n",
    "        names = load_names_from_yaml(DATA_YAML)\n",
    "        if names:\n",
    "            CLASS_NAMES = names\n",
    "            print(\"Classes (do YAML):\", CLASS_NAMES)\n",
    "        else:\n",
    "            CLASS_NAMES = [\"classe_A\", \"classe_B\"]\n",
    "            print(\"Classes (default):\", CLASS_NAMES)\n",
    "    except:\n",
    "        CLASS_NAMES = [\"classe_A\", \"classe_B\"]\n",
    "        print(\"Classes (default):\", CLASS_NAMES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95d0d4a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import time\n",
    "from contextlib import contextmanager\n",
    "\n",
    "@contextmanager\n",
    "def timer(label):\n",
    "    start = time.time()\n",
    "    yield\n",
    "    end = time.time()\n",
    "    print(f\"[TIMER] {label}: {end - start:.2f} s\")\n",
    "\n",
    "def ms_per_image(seconds, n_images):\n",
    "    return (seconds / max(1, n_images)) * 1000.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "397be221",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "BEST_WEIGHTS = \"{latest_run}/weights/best.pt\"  \n",
    "\n",
    "# Avaliação com yolov5 val.py\n",
    "!python yolov5/val.py --weights \"{BEST_WEIGHTS}\" --data \"{DATA_YAML}\" --img {IMG_SIZE_YOLO} --task test --verbose --save-json\n",
    "\n",
    "# Inferência em imagens de teste (para prints)\n",
    "TEST_SOURCE = f\"{DATASET_DIR}/test\"\n",
    "!python yolov5/detect.py --weights \"{BEST_WEIGHTS}\" --img {IMG_SIZE_YOLO} --conf 0.25 --source \"{TEST_SOURCE}\" --save-txt --save-conf\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39cfa7b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os, json, time\n",
    "\n",
    "results_rows = []\n",
    "\n",
    "for E in EPOCHS_LIST:\n",
    "    print(f\"\\n=== Treinando YOLOv5s por {E} épocas ===\")\n",
    "    with timer(f\"YOLOv5s treino {E} épocas\"):\n",
    "        !python yolov5/train.py --data \"{DATA_YAML}\" --weights yolov5s.pt --img {IMG_SIZE_YOLO} --epochs {E} --project yolov5/runs/train --name yolo_baseline_{E} --exist-ok\n",
    "    \n",
    "    # Validação no conjunto de teste\n",
    "    with timer(f\"YOLOv5s val (test) {E} épocas\"):\n",
    "        !python yolov5/val.py --weights \"yolov5/runs/train/yolo_baseline_{E}/weights/best.pt\" --data \"{DATA_YAML}\" --img {IMG_SIZE_YOLO} --task test --verbose --save-json\n",
    "\n",
    "print(\"Treinos baseline concluídos. Verifique pastas em yolov5/runs/train/.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85fe50fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os, shutil, glob\n",
    "from collections import Counter\n",
    "from pathlib import Path\n",
    "\n",
    "YOLO_IMAGES = {\n",
    "    \"train\": f\"{DATASET_DIR}/images/train\",\n",
    "    \"val\":   f\"{DATASET_DIR}/images/val\",\n",
    "    \"test\":  f\"{DATASET_DIR}/images/test\"\n",
    "}\n",
    "YOLO_LABELS = {\n",
    "    \"train\": f\"{DATASET_DIR}/labels/train\",\n",
    "    \"val\":   f\"{DATASET_DIR}/labels/val\",\n",
    "    \"test\":  f\"{DATASET_DIR}/labels/test\"\n",
    "}\n",
    "\n",
    "# Saída para classificação\n",
    "CLS_ROOT = \"/content/classification_ds\"\n",
    "for split in [\"train\",\"val\",\"test\"]:\n",
    "    for cname in CLASS_NAMES:\n",
    "        os.makedirs(f\"{CLS_ROOT}/{split}/{cname}\", exist_ok=True)\n",
    "\n",
    "def infer_image_label_from_yolo(txt_path):\n",
    "    try:\n",
    "        lines = Path(txt_path).read_text().strip().splitlines()\n",
    "        if not lines:\n",
    "            return None\n",
    "        classes = [int(line.split()[0]) for line in lines if line.strip()]\n",
    "        if not classes:\n",
    "            return None\n",
    "        maj = Counter(classes).most_common(1)[0][0]\n",
    "        if maj < len(CLASS_NAMES):\n",
    "            return CLASS_NAMES[maj]\n",
    "    except Exception as e:\n",
    "        return None\n",
    "    return None\n",
    "\n",
    "def build_classification_split(split):\n",
    "    img_dir = YOLO_IMAGES[split]\n",
    "    lbl_dir = YOLO_LABELS[split]\n",
    "    images = glob.glob(os.path.join(img_dir, \"*.*\"))\n",
    "    copied = 0\n",
    "    for img in images:\n",
    "        stem = Path(img).stem\n",
    "        txt = os.path.join(lbl_dir, stem + \".txt\")\n",
    "        if not os.path.exists(txt):\n",
    "            continue\n",
    "        cname = infer_image_label_from_yolo(txt)\n",
    "        if cname is None:\n",
    "            continue\n",
    "        dst = os.path.join(CLS_ROOT, split, cname, os.path.basename(img))\n",
    "        shutil.copy2(img, dst)\n",
    "        copied += 1\n",
    "    print(f\"[{split}] copiados {copied} arquivos.\")\n",
    "\n",
    "for sp in [\"train\",\"val\",\"test\"]:\n",
    "    build_classification_split(sp)\n",
    "\n",
    "print(\"Estrutura para classificação criada em:\", CLS_ROOT)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed8b7e1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "!pip install torchmetrics -q\n",
    "\n",
    "import torch, torch.nn as nn, torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms, models\n",
    "from torchmetrics.classification import BinaryF1Score, BinaryPrecision, BinaryRecall\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Device:\", device)\n",
    "\n",
    "# Transforms\n",
    "train_tf = transforms.Compose([\n",
    "    transforms.Resize((IMG_SIZE_CNN, IMG_SIZE_CNN)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "eval_tf = transforms.Compose([\n",
    "    transforms.Resize((IMG_SIZE_CNN, IMG_SIZE_CNN)),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "train_ds = datasets.ImageFolder(f\"{CLS_ROOT}/train\", transform=train_tf)\n",
    "val_ds   = datasets.ImageFolder(f\"{CLS_ROOT}/val\",   transform=eval_tf)\n",
    "test_ds  = datasets.ImageFolder(f\"{CLS_ROOT}/test\",  transform=eval_tf)\n",
    "\n",
    "train_dl = DataLoader(train_ds, batch_size=32, shuffle=True, num_workers=2, pin_memory=True)\n",
    "val_dl   = DataLoader(val_ds,   batch_size=32, shuffle=False, num_workers=2, pin_memory=True)\n",
    "test_dl  = DataLoader(test_ds,  batch_size=32, shuffle=False, num_workers=2, pin_memory=True)\n",
    "\n",
    "# CNN simples\n",
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self, n_classes=2):\n",
    "        super().__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(3, 16, 3, padding=1), nn.ReLU(), nn.MaxPool2d(2),\n",
    "            nn.Conv2d(16, 32, 3, padding=1), nn.ReLU(), nn.MaxPool2d(2),\n",
    "            nn.Conv2d(32, 64, 3, padding=1), nn.ReLU(), nn.MaxPool2d(2),\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(64*(IMG_SIZE_CNN//8)*(IMG_SIZE_CNN//8), 128), nn.ReLU(), nn.Dropout(0.3),\n",
    "            nn.Linear(128, n_classes)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "model = SimpleCNN(n_classes=2).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "def evaluate(loader):\n",
    "    model.eval()\n",
    "    total, correct = 0,0\n",
    "    all_probs = []\n",
    "    all_labels = []\n",
    "    with torch.no_grad():\n",
    "        for x,y in loader:\n",
    "            x,y = x.to(device), y.to(device)\n",
    "            logits = model(x)\n",
    "            probs = torch.softmax(logits, dim=1)[:,1]\n",
    "            preds = torch.argmax(logits, dim=1)\n",
    "            correct += (preds == y).sum().item()\n",
    "            total += y.size(0)\n",
    "            all_probs.append(probs.detach().cpu())\n",
    "            all_labels.append(y.detach().cpu())\n",
    "    import torch\n",
    "    probs = torch.cat(all_probs)\n",
    "    labels = torch.cat(all_labels)\n",
    "    # Para binário, classe \"1\" é a segunda pasta em train_ds.classes\n",
    "    f1 = BinaryF1Score().to('cpu')(probs, labels).item()\n",
    "    prec = BinaryPrecision().to('cpu')(probs, labels).item()\n",
    "    rec = BinaryRecall().to('cpu')(probs, labels).item()\n",
    "    acc = correct/total if total>0 else 0\n",
    "    return {\"acc\":acc, \"f1\":f1, \"precision\":prec, \"recall\":rec}\n",
    "\n",
    "history = []\n",
    "for E in EPOCHS_LIST:  # treinar duas variações (30 e 60)\n",
    "    print(f\"\\n=== CNN treino por {E} épocas ===\")\n",
    "    model = SimpleCNN(n_classes=2).to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "    with timer(f\"CNN treino {E} épocas\"):\n",
    "        for epoch in range(E):\n",
    "            model.train()\n",
    "            running = 0.0\n",
    "            for x,y in train_dl:\n",
    "                x,y = x.to(device), y.to(device)\n",
    "                optimizer.zero_grad()\n",
    "                logits = model(x)\n",
    "                loss = criterion(logits, y)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                running += loss.item()*y.size(0)\n",
    "            if (epoch+1)%10==0 or epoch==0:\n",
    "                val_metrics = evaluate(val_dl)\n",
    "                print(f\"Epoch {epoch+1}/{E} - Val: {val_metrics}\")\n",
    "\n",
    "    test_metrics = evaluate(test_dl)\n",
    "    print(f\"[CNN] Test ({E} épocas):\", test_metrics)\n",
    "    row = {\"approach\":\"CNN\", \"epochs\":E, **test_metrics}\n",
    "    history.append(row)\n",
    "\n",
    "pd.DataFrame(history)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbcf3b05",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cols = [\"approach\",\"epochs\",\"acc\",\"f1\",\"precision\",\"recall\",\"notes\"]\n",
    "df = pd.DataFrame(columns=cols)\n",
    "\n",
    "# Exemplos (substitua pelos seus resultados reais)\n",
    "df = pd.concat([\n",
    "    pd.DataFrame([{\"approach\":\"YOLO custom (E1)\",\"epochs\":\"-\", \"acc\":None,\"f1\":None,\"precision\":None,\"recall\":None,\"notes\":\"mAP@0.5 ~ X; ver val.py\"}]),\n",
    "    pd.DataFrame([{\"approach\":\"YOLO baseline\",\"epochs\":30, \"acc\":None,\"f1\":None,\"precision\":None,\"recall\":None,\"notes\":\"mAP@0.5 ~ ?\"}]),\n",
    "    pd.DataFrame([{\"approach\":\"YOLO baseline\",\"epochs\":60, \"acc\":None,\"f1\":None,\"precision\":None,\"recall\":None,\"notes\":\"mAP@0.5 ~ ?\"}]),\n",
    "    pd.DataFrame([{\"approach\":\"CNN\",\"epochs\":30, \"acc\":None,\"f1\":None,\"precision\":None,\"recall\":None,\"notes\":\"preencher com teste\"}]),\n",
    "    pd.DataFrame([{\"approach\":\"CNN\",\"epochs\":60, \"acc\":None,\"f1\":None,\"precision\":None,\"recall\":None,\"notes\":\"preencher com teste\"}]),\n",
    "], ignore_index=True)\n",
    "\n",
    "print(\"Preencha os campos com os números obtidos nas seções anteriores.\")\n",
    "df\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
